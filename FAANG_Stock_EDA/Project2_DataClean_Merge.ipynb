{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aed93b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "432ea523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for each FAANG stock dataset and interest rate dataset.\n",
    "# Interest rate dataset has notes in first 15 rows. Data headings and data starts in row 16 and below.\n",
    "\n",
    "amazon = pd.read_csv(\"Amazon.csv\")\n",
    "apple = pd.read_csv(\"Apple.csv\")\n",
    "facebook = pd.read_csv(\"Facebook.csv\")\n",
    "google = pd.read_csv(\"Google.csv\")\n",
    "netflix = pd.read_csv(\"Netflix.csv\")\n",
    "interest = pd.read_csv(\"fed-funds-rate-historical-chart.csv\", skiprows=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71801eba",
   "metadata": {},
   "source": [
    "# Let's first review stock datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfb0a101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5852 entries, 0 to 5851\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       5852 non-null   object \n",
      " 1   Open       5852 non-null   float64\n",
      " 2   High       5852 non-null   float64\n",
      " 3   Low        5852 non-null   float64\n",
      " 4   Close      5852 non-null   float64\n",
      " 5   Adj Close  5852 non-null   float64\n",
      " 6   Volume     5852 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 320.2+ KB\n",
      "None \n",
      "\n",
      "--------------------------------------------------\n",
      "Apple:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10016 entries, 0 to 10015\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       10016 non-null  object \n",
      " 1   Open       10015 non-null  float64\n",
      " 2   High       10015 non-null  float64\n",
      " 3   Low        10015 non-null  float64\n",
      " 4   Close      10015 non-null  float64\n",
      " 5   Adj Close  10015 non-null  float64\n",
      " 6   Volume     10015 non-null  float64\n",
      "dtypes: float64(6), object(1)\n",
      "memory usage: 547.9+ KB\n",
      "None \n",
      "\n",
      "--------------------------------------------------\n",
      "Facebook:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2076 entries, 0 to 2075\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       2076 non-null   object \n",
      " 1   Open       2076 non-null   float64\n",
      " 2   High       2076 non-null   float64\n",
      " 3   Low        2076 non-null   float64\n",
      " 4   Close      2076 non-null   float64\n",
      " 5   Adj Close  2076 non-null   float64\n",
      " 6   Volume     2076 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 113.7+ KB\n",
      "None \n",
      "\n",
      "--------------------------------------------------\n",
      "Google:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4041 entries, 0 to 4040\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       4041 non-null   object \n",
      " 1   Open       4041 non-null   float64\n",
      " 2   High       4041 non-null   float64\n",
      " 3   Low        4041 non-null   float64\n",
      " 4   Close      4041 non-null   float64\n",
      " 5   Adj Close  4041 non-null   float64\n",
      " 6   Volume     4041 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 221.1+ KB\n",
      "None \n",
      "\n",
      "--------------------------------------------------\n",
      "Netflix:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4581 entries, 0 to 4580\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       4581 non-null   object \n",
      " 1   Open       4581 non-null   float64\n",
      " 2   High       4581 non-null   float64\n",
      " 3   Low        4581 non-null   float64\n",
      " 4   Close      4581 non-null   float64\n",
      " 5   Adj Close  4581 non-null   float64\n",
      " 6   Volume     4581 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 250.6+ KB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at column names/counts, nulls in each column, and datatypes for each company.\n",
    "\n",
    "print(\"Amazon:\\n\")\n",
    "print(amazon.info(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Apple:\\n\")\n",
    "print(apple.info(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Facebook:\\n\")\n",
    "print(facebook.info(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Google:\\n\")\n",
    "print(google.info(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Netflix:\\n\")\n",
    "print(netflix.info(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a3ecc",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "1. All FAANG datasets have same number of columns and column names.\n",
    "2. All datatypes of each column are consistent across each dataset, except Apple's Volume column is a float while the other datasets are integer.\n",
    "3. 'Date' column in each dataset is not datetime type.\n",
    "4. 'Adj Close' column has a space which may not be best.\n",
    "5. There is one instance of null values in the Apple dataset.\n",
    "6. Many columns not needed for our analysis. We do not plan to analyze intra-day changes, so can remove 'Open', 'High' and 'Low' columns. We will be looking at 'Adj Close' instead of 'Close' so can remove 'Close' column.\n",
    "7. Probably want to rename column headings specific to each stock to uniquely identify when created merged dataframe ('Apple_Adj_Close', etc.). \n",
    "\n",
    "#### To do:\n",
    "1. Change 'Adj Close' column to remove space for cleaner syntax/manipulation.\n",
    "2. Change 'Date' column to datetime type.\n",
    "3. Look into null values in Apple dataset.\n",
    "4. Make Apple's Volume datatype an integer like the other datasets?\n",
    "5. Drop 'Open', 'High', 'Low and 'Close' columns.\n",
    "6. Rename headings in each stock dataset to specific stock ('Apple_Adj_close', etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7894da6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon:\n",
      "\n",
      "         Date      Open      High       Low     Close  Adj Close    Volume\n",
      "0  1997-05-15  2.437500  2.500000  1.927083  1.958333   1.958333  72156000\n",
      "1  1997-05-16  1.968750  1.979167  1.708333  1.729167   1.729167  14700000\n",
      "2  1997-05-19  1.760417  1.770833  1.625000  1.708333   1.708333   6106800\n",
      "3  1997-05-20  1.729167  1.750000  1.635417  1.635417   1.635417   5467200\n",
      "4  1997-05-21  1.635417  1.645833  1.375000  1.427083   1.427083  18853200 \n",
      "\n",
      "--------------------------------------------------\n",
      "Apple:\n",
      "\n",
      "         Date      Open      High       Low     Close  Adj Close       Volume\n",
      "0  1980-12-12  0.128348  0.128906  0.128348  0.128348   0.101261  469033600.0\n",
      "1  1980-12-15  0.122210  0.122210  0.121652  0.121652   0.095978  175884800.0\n",
      "2  1980-12-16  0.113281  0.113281  0.112723  0.112723   0.088934  105728000.0\n",
      "3  1980-12-17  0.115513  0.116071  0.115513  0.115513   0.091135   86441600.0\n",
      "4  1980-12-18  0.118862  0.119420  0.118862  0.118862   0.093777   73449600.0 \n",
      "\n",
      "--------------------------------------------------\n",
      "Facebook:\n",
      "\n",
      "         Date       Open       High        Low      Close  Adj Close  \\\n",
      "0  2012-05-18  42.049999  45.000000  38.000000  38.230000  38.230000   \n",
      "1  2012-05-21  36.529999  36.660000  33.000000  34.029999  34.029999   \n",
      "2  2012-05-22  32.610001  33.590000  30.940001  31.000000  31.000000   \n",
      "3  2012-05-23  31.370001  32.500000  31.360001  32.000000  32.000000   \n",
      "4  2012-05-24  32.950001  33.209999  31.770000  33.029999  33.029999   \n",
      "\n",
      "      Volume  \n",
      "0  573576400  \n",
      "1  168192700  \n",
      "2  101786600  \n",
      "3   73600000  \n",
      "4   50237200   \n",
      "\n",
      "--------------------------------------------------\n",
      "Google:\n",
      "\n",
      "         Date       Open       High        Low      Close  Adj Close    Volume\n",
      "0  2004-08-19  50.050049  52.082081  48.028027  50.220219  50.220219  44659000\n",
      "1  2004-08-20  50.555557  54.594593  50.300301  54.209209  54.209209  22834300\n",
      "2  2004-08-23  55.430431  56.796795  54.579578  54.754753  54.754753  18256100\n",
      "3  2004-08-24  55.675674  55.855854  51.836838  52.487488  52.487488  15247300\n",
      "4  2004-08-25  52.532532  54.054054  51.991993  53.053055  53.053055   9188600 \n",
      "\n",
      "--------------------------------------------------\n",
      "Netflix:\n",
      "\n",
      "         Date      Open      High       Low     Close  Adj Close     Volume\n",
      "0  2002-05-23  1.156429  1.242857  1.145714  1.196429   1.196429  104790000\n",
      "1  2002-05-24  1.214286  1.225000  1.197143  1.210000   1.210000   11104800\n",
      "2  2002-05-28  1.213571  1.232143  1.157143  1.157143   1.157143    6609400\n",
      "3  2002-05-29  1.164286  1.164286  1.085714  1.103571   1.103571    6757800\n",
      "4  2002-05-30  1.107857  1.107857  1.071429  1.071429   1.071429   10154200 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Glance at rows of data for each company.\n",
    "\n",
    "print(\"Amazon:\\n\")\n",
    "print(amazon.sort_values(\"Date\").head(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Apple:\\n\")\n",
    "print(apple.sort_values(\"Date\").head(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Facebook:\\n\")\n",
    "print(facebook.sort_values(\"Date\").head(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Google:\\n\")\n",
    "print(google.sort_values(\"Date\").head(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Netflix:\\n\")\n",
    "print(netflix.sort_values(\"Date\").head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a828212",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "1. Looks like the starting dates of data vary across datasets.\n",
    "2. There are a lot of decimals for float columns.\n",
    "3. We see the 'Volume' column for Apple as a float here.\n",
    "\n",
    "#### To do (Cumulative):\n",
    "1. Change 'Adj Close' column to remove space for cleaner syntax/manipulation.\n",
    "2. Change 'Date' column to datetime type.\n",
    "3. Look into null values in Apple dataset.\n",
    "4. Make Apple's Volume datatype an integer like the other datasets?\n",
    "5. Drop 'Open', 'High', 'Low' and 'Close' columns.\n",
    "6. Rename headings in each stock dataset to specific stock ('Apple_Adj_close', etc.).\n",
    "7. Round all float columns to 2 decimals (more intuitive and cleaner visually).\n",
    "8. Consider only including dates where we have data across all stocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3eb3ccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon:\n",
      "\n",
      "1997-05-15    1\n",
      "2012-11-27    1\n",
      "2012-11-23    1\n",
      "2012-11-21    1\n",
      "2012-11-20    1\n",
      "             ..\n",
      "2005-02-11    1\n",
      "2005-02-10    1\n",
      "2005-02-09    1\n",
      "2005-02-08    1\n",
      "2020-08-14    1\n",
      "Name: Date, Length: 5852, dtype: int64 \n",
      "\n",
      "--------------------------------------------------\n",
      "Apple:\n",
      "\n",
      "1980-12-12    1\n",
      "2007-06-05    1\n",
      "2007-05-24    1\n",
      "2007-05-25    1\n",
      "2007-05-29    1\n",
      "             ..\n",
      "1994-02-25    1\n",
      "1994-02-28    1\n",
      "1994-03-01    1\n",
      "1994-03-02    1\n",
      "2020-09-01    1\n",
      "Name: Date, Length: 10016, dtype: int64 \n",
      "\n",
      "--------------------------------------------------\n",
      "Facebook:\n",
      "\n",
      "2012-05-18    1\n",
      "2017-10-18    1\n",
      "2017-11-30    1\n",
      "2017-11-29    1\n",
      "2017-11-28    1\n",
      "             ..\n",
      "2015-02-11    1\n",
      "2015-02-10    1\n",
      "2015-02-09    1\n",
      "2015-02-06    1\n",
      "2020-08-18    1\n",
      "Name: Date, Length: 2076, dtype: int64 \n",
      "\n",
      "--------------------------------------------------\n",
      "Google:\n",
      "\n",
      "2004-08-19    1\n",
      "2015-05-11    1\n",
      "2015-04-22    1\n",
      "2015-04-23    1\n",
      "2015-04-24    1\n",
      "             ..\n",
      "2009-12-31    1\n",
      "2010-01-04    1\n",
      "2010-01-05    1\n",
      "2010-01-06    1\n",
      "2020-09-04    1\n",
      "Name: Date, Length: 4041, dtype: int64 \n",
      "\n",
      "--------------------------------------------------\n",
      "Netflix:\n",
      "\n",
      "2002-05-23    1\n",
      "2014-07-09    1\n",
      "2014-07-17    1\n",
      "2014-07-16    1\n",
      "2014-07-15    1\n",
      "             ..\n",
      "2008-06-25    1\n",
      "2008-06-26    1\n",
      "2008-06-27    1\n",
      "2008-06-30    1\n",
      "2020-08-03    1\n",
      "Name: Date, Length: 4581, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confirm no duplicate date entries\n",
    "\n",
    "print(\"Amazon:\\n\")\n",
    "print(amazon[\"Date\"].value_counts(dropna=False), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Apple:\\n\")\n",
    "print(apple[\"Date\"].value_counts(dropna=False), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Facebook:\\n\")\n",
    "print(facebook[\"Date\"].value_counts(dropna=False), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Google:\\n\")\n",
    "print(google[\"Date\"].value_counts(dropna=False), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Netflix:\\n\")\n",
    "print(netflix[\"Date\"].value_counts(dropna=False), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f86739",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "1. No duplicate date entries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1831e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon:\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Date, Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: [] \n",
      "\n",
      "--------------------------------------------------\n",
      "Apple:\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Date, Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: [] \n",
      "\n",
      "--------------------------------------------------\n",
      "Facebook:\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Date, Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: [] \n",
      "\n",
      "--------------------------------------------------\n",
      "Google:\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Date, Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: [] \n",
      "\n",
      "--------------------------------------------------\n",
      "Netflix:\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Date, Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confirm no negative values for 'Adj Close' or 'Volume' columns\n",
    "\n",
    "print(\"Amazon:\\n\")\n",
    "print(amazon[(amazon[\"Adj Close\"] < 0) | (amazon[\"Volume\"] < 0)], \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Apple:\\n\")\n",
    "print(apple[(apple[\"Adj Close\"] < 0) | (apple[\"Volume\"] < 0)], \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Facebook:\\n\")\n",
    "print(facebook[(facebook[\"Adj Close\"] < 0) | (facebook[\"Volume\"] < 0)], \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Google:\\n\")\n",
    "print(google[(google[\"Adj Close\"] < 0) | (google[\"Volume\"] < 0)], \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Netflix:\\n\")\n",
    "print(netflix[(netflix[\"Adj Close\"] < 0) | (netflix[\"Volume\"] < 0)], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7466efd",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "1. No negative values in 'Adj Close' or 'Volume' columns like expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31277e26",
   "metadata": {},
   "source": [
    "# Let's clean stock datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de50d7a",
   "metadata": {},
   "source": [
    "#### To do list (Cumulative):\n",
    "1. Change 'Adj Close' column to remove space for cleaner syntax/manipulation.\n",
    "2. Change 'Date' column to datetime type.\n",
    "3. Look into null values in Apple dataset.\n",
    "4. Make Apple's Volume datatype an integer like the other datasets?\n",
    "5. Drop 'Open', 'High', 'Low' and 'Close' columns.\n",
    "6. Rename headings in each stock dataset to specific stock ('Apple_Adj_close', etc.).\n",
    "7. Round all float columns to 2 decimals (more intuitive and cleaner visually).\n",
    "8. Consider only including dates where we have data across all stocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd8554f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon:\n",
      "\n",
      "Index(['Date', 'Adj Close', 'Volume'], dtype='object') \n",
      "\n",
      "--------------------------------------------------\n",
      "Apple:\n",
      "\n",
      "Index(['Date', 'Adj Close', 'Volume'], dtype='object') \n",
      "\n",
      "--------------------------------------------------\n",
      "Facebook:\n",
      "\n",
      "Index(['Date', 'Adj Close', 'Volume'], dtype='object') \n",
      "\n",
      "--------------------------------------------------\n",
      "Google:\n",
      "\n",
      "Index(['Date', 'Adj Close', 'Volume'], dtype='object') \n",
      "\n",
      "--------------------------------------------------\n",
      "Netflix:\n",
      "\n",
      "Index(['Date', 'Adj Close', 'Volume'], dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop columns not needed\n",
    "\n",
    "amazon_clean = amazon.drop([\"Open\",\"High\",\"Low\",\"Close\"], axis=1)\n",
    "apple_clean = apple.drop([\"Open\",\"High\",\"Low\",\"Close\"], axis=1)\n",
    "facebook_clean = facebook.drop([\"Open\",\"High\",\"Low\",\"Close\"], axis=1)\n",
    "google_clean = google.drop([\"Open\",\"High\",\"Low\",\"Close\"], axis=1)\n",
    "netflix_clean = netflix.drop([\"Open\",\"High\",\"Low\",\"Close\"], axis=1)\n",
    "\n",
    "print(\"Amazon:\\n\")\n",
    "print(amazon_clean.columns, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Apple:\\n\")\n",
    "print(apple_clean.columns, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Facebook:\\n\")\n",
    "print(facebook_clean.columns, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Google:\\n\")\n",
    "print(google_clean.columns, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Netflix:\\n\")\n",
    "print(netflix_clean.columns, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abcc240f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon:\n",
      "\n",
      "Index(['Date', 'Amazon_Adj_Close', 'Amazon_Vol'], dtype='object') \n",
      "\n",
      "--------------------------------------------------\n",
      "Apple:\n",
      "\n",
      "Index(['Date', 'Apple_Adj_Close', 'Apple_Vol'], dtype='object') \n",
      "\n",
      "--------------------------------------------------\n",
      "Facebook:\n",
      "\n",
      "Index(['Date', 'Facebook_Adj_Close', 'Facebook_Vol'], dtype='object') \n",
      "\n",
      "--------------------------------------------------\n",
      "Google:\n",
      "\n",
      "Index(['Date', 'Google_Adj_Close', 'Google_Vol'], dtype='object') \n",
      "\n",
      "--------------------------------------------------\n",
      "Netflix:\n",
      "\n",
      "Index(['Date', 'Netflix_Adj_Close', 'Netflix_Vol'], dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename headings in each stock dataset to specific stock ('Apple_Adj_close', etc.)\n",
    "\n",
    "amazon_clean = amazon_clean.rename(columns = {\"Adj Close\": \"Amazon_Adj_Close\", \"Volume\":\"Amazon_Vol\"})\n",
    "apple_clean = apple_clean.rename(columns = {\"Adj Close\": \"Apple_Adj_Close\", \"Volume\":\"Apple_Vol\"})\n",
    "facebook_clean = facebook_clean.rename(columns = {\"Adj Close\": \"Facebook_Adj_Close\", \"Volume\":\"Facebook_Vol\"})\n",
    "google_clean = google_clean.rename(columns = {\"Adj Close\": \"Google_Adj_Close\", \"Volume\":\"Google_Vol\"})\n",
    "netflix_clean = netflix_clean.rename(columns = {\"Adj Close\": \"Netflix_Adj_Close\", \"Volume\":\"Netflix_Vol\"})\n",
    "\n",
    "print(\"Amazon:\\n\")\n",
    "print(amazon_clean.columns, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Apple:\\n\")\n",
    "print(apple_clean.columns, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Facebook:\\n\")\n",
    "print(facebook_clean.columns, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Google:\\n\")\n",
    "print(google_clean.columns, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Netflix:\\n\")\n",
    "print(netflix_clean.columns, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba270e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon:\n",
      "\n",
      "datetime64[ns] \n",
      "\n",
      "--------------------------------------------------\n",
      "Apple:\n",
      "\n",
      "datetime64[ns] \n",
      "\n",
      "--------------------------------------------------\n",
      "Facebook:\n",
      "\n",
      "datetime64[ns] \n",
      "\n",
      "--------------------------------------------------\n",
      "Google:\n",
      "\n",
      "datetime64[ns] \n",
      "\n",
      "--------------------------------------------------\n",
      "Netflix:\n",
      "\n",
      "datetime64[ns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change 'Date' column to datetime type.\n",
    "\n",
    "amazon_clean[\"Date\"] = pd.to_datetime(amazon_clean[\"Date\"])\n",
    "apple_clean[\"Date\"] = pd.to_datetime(apple_clean[\"Date\"])\n",
    "facebook_clean[\"Date\"] = pd.to_datetime(facebook_clean[\"Date\"])\n",
    "google_clean[\"Date\"] = pd.to_datetime(google_clean[\"Date\"])\n",
    "netflix_clean[\"Date\"] = pd.to_datetime(netflix_clean[\"Date\"])\n",
    "\n",
    "print(\"Amazon:\\n\")\n",
    "print(amazon_clean[\"Date\"].dtypes, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Apple:\\n\")\n",
    "print(apple_clean[\"Date\"].dtypes, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Facebook:\\n\")\n",
    "print(facebook_clean[\"Date\"].dtypes, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Google:\\n\")\n",
    "print(google_clean[\"Date\"].dtypes, \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Netflix:\\n\")\n",
    "print(netflix_clean[\"Date\"].dtypes, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b284ae72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10016 entries, 0 to 10015\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Date             10016 non-null  datetime64[ns]\n",
      " 1   Apple_Adj_Close  10015 non-null  float64       \n",
      " 2   Apple_Vol        10015 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2)\n",
      "memory usage: 234.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Remove null rows in Apple dataset\n",
    "\n",
    "apple_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9588ae70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Apple_Adj_Close</th>\n",
       "      <th>Apple_Vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1981-08-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Apple_Adj_Close  Apple_Vol\n",
       "165 1981-08-10              NaN        NaN"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_clean[apple_clean[\"Apple_Adj_Close\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bac7b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_clean = apple_clean.drop(165, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d29016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10015 entries, 0 to 10015\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Date             10015 non-null  datetime64[ns]\n",
      " 1   Apple_Adj_Close  10015 non-null  float64       \n",
      " 2   Apple_Vol        10015 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2)\n",
      "memory usage: 313.0 KB\n"
     ]
    }
   ],
   "source": [
    "apple_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "618f37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Apple's Volume datatype an integer like the other datasets.\n",
    "\n",
    "apple_clean[\"Apple_Vol\"] = apple_clean[\"Apple_Vol\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dffd0030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10015 entries, 0 to 10015\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Date             10015 non-null  datetime64[ns]\n",
      " 1   Apple_Adj_Close  10015 non-null  float64       \n",
      " 2   Apple_Vol        10015 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
      "memory usage: 313.0 KB\n"
     ]
    }
   ],
   "source": [
    "apple_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "09cd36d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Apple_Adj_Close</th>\n",
       "      <th>Apple_Vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>0.101261</td>\n",
       "      <td>469033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>0.095978</td>\n",
       "      <td>175884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>0.088934</td>\n",
       "      <td>105728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>0.091135</td>\n",
       "      <td>86441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>0.093777</td>\n",
       "      <td>73449600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Apple_Adj_Close  Apple_Vol\n",
       "0 1980-12-12         0.101261  469033600\n",
       "1 1980-12-15         0.095978  175884800\n",
       "2 1980-12-16         0.088934  105728000\n",
       "3 1980-12-17         0.091135   86441600\n",
       "4 1980-12-18         0.093777   73449600"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d2190501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon:\n",
      "\n",
      "        Date  Amazon_Adj_Close  Amazon_Vol\n",
      "0 1997-05-15              1.96    72156000\n",
      "1 1997-05-16              1.73    14700000\n",
      "2 1997-05-19              1.71     6106800\n",
      "3 1997-05-20              1.64     5467200\n",
      "4 1997-05-21              1.43    18853200 \n",
      "\n",
      "--------------------------------------------------\n",
      "Apple:\n",
      "\n",
      "        Date  Apple_Adj_Close  Apple_Vol\n",
      "0 1980-12-12             0.10  469033600\n",
      "1 1980-12-15             0.10  175884800\n",
      "2 1980-12-16             0.09  105728000\n",
      "3 1980-12-17             0.09   86441600\n",
      "4 1980-12-18             0.09   73449600 \n",
      "\n",
      "--------------------------------------------------\n",
      "Facebook:\n",
      "\n",
      "        Date  Facebook_Adj_Close  Facebook_Vol\n",
      "0 2012-05-18               38.23     573576400\n",
      "1 2012-05-21               34.03     168192700\n",
      "2 2012-05-22               31.00     101786600\n",
      "3 2012-05-23               32.00      73600000\n",
      "4 2012-05-24               33.03      50237200 \n",
      "\n",
      "--------------------------------------------------\n",
      "Google:\n",
      "\n",
      "        Date  Google_Adj_Close  Google_Vol\n",
      "0 2004-08-19             50.22    44659000\n",
      "1 2004-08-20             54.21    22834300\n",
      "2 2004-08-23             54.75    18256100\n",
      "3 2004-08-24             52.49    15247300\n",
      "4 2004-08-25             53.05     9188600 \n",
      "\n",
      "--------------------------------------------------\n",
      "Netflix:\n",
      "\n",
      "        Date  Netflix_Adj_Close  Netflix_Vol\n",
      "0 2002-05-23               1.20    104790000\n",
      "1 2002-05-24               1.21     11104800\n",
      "2 2002-05-28               1.16      6609400\n",
      "3 2002-05-29               1.10      6757800\n",
      "4 2002-05-30               1.07     10154200 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Round all float columns to 2 decimals (more intuitive and cleaner visually)\n",
    "\n",
    "amazon_clean[\"Amazon_Adj_Close\"] = amazon_clean[\"Amazon_Adj_Close\"].round(2)\n",
    "apple_clean[\"Apple_Adj_Close\"] = apple_clean[\"Apple_Adj_Close\"].round(2)\n",
    "facebook_clean[\"Facebook_Adj_Close\"] = facebook_clean[\"Facebook_Adj_Close\"].round(2)\n",
    "google_clean[\"Google_Adj_Close\"] = google_clean[\"Google_Adj_Close\"].round(2)\n",
    "netflix_clean[\"Netflix_Adj_Close\"] = netflix_clean[\"Netflix_Adj_Close\"].round(2)\n",
    "\n",
    "print(\"Amazon:\\n\")\n",
    "print(amazon_clean.sort_values(\"Date\").head(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Apple:\\n\")\n",
    "print(apple_clean.sort_values(\"Date\").head(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Facebook:\\n\")\n",
    "print(facebook_clean.sort_values(\"Date\").head(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Google:\\n\")\n",
    "print(google_clean.sort_values(\"Date\").head(), \"\\n\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Netflix:\\n\")\n",
    "print(netflix_clean.sort_values(\"Date\").head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e124f2f3",
   "metadata": {},
   "source": [
    "# Let's review interest rate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2463e664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interest Rates:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24483 entries, 0 to 24482\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   date    24483 non-null  object \n",
      " 1    value  24462 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 382.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Look at column names/counts, nulls in each column, and datatypes.\n",
    "\n",
    "print(\"Interest Rates:\\n\")\n",
    "print(interest.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa769f5",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "1. Column names can be changed: 'date' column different than 'Date' in stock datasets and ' value' column not clear and has extra whitespace in name.\n",
    "2. 'date' column is not datetime type.\n",
    "3. There are null values in the 'value' column.\n",
    "\n",
    "#### To do:\n",
    "1. Change 'date' column name to \"Date\".\n",
    "2. Change ' value' column name to \"Int_Rate\".\n",
    "3. Change 'date' column to datetime type.\n",
    "4. Look into null values in 'value' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "434ed65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interest Rates:\n",
      "\n",
      "         date   value\n",
      "0  1954-07-01    1.13\n",
      "1  1954-07-02    1.25\n",
      "2  1954-07-03    1.25\n",
      "3  1954-07-04    1.25\n",
      "4  1954-07-05    0.88\n",
      "5  1954-07-06    0.25\n",
      "6  1954-07-07    1.00\n",
      "7  1954-07-08    1.25\n",
      "8  1954-07-09    1.25\n",
      "9  1954-07-10    1.25\n",
      "             date   value\n",
      "24473  2022-11-21     NaN\n",
      "24474  2022-11-22     NaN\n",
      "24475  2022-11-23     NaN\n",
      "24476  2022-11-24     NaN\n",
      "24477  2022-11-25     NaN\n",
      "24478  2022-11-26     NaN\n",
      "24479  2022-11-27     NaN\n",
      "24480  2022-11-28     NaN\n",
      "24481  2022-11-29     NaN\n",
      "24482  2022-11-30     NaN\n"
     ]
    }
   ],
   "source": [
    "# Glance at rows of data.\n",
    "\n",
    "print(\"Interest Rates:\\n\")\n",
    "print(interest.sort_values(\"date\").head(10))\n",
    "print(interest.sort_values(\"date\").tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "aa794204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  0.04\n",
      "Max:  22.36\n",
      "Mean:  4.669059357370667\n"
     ]
    }
   ],
   "source": [
    "# Look at min, max and mean of interest rates\n",
    "\n",
    "print(\"Min: \", interest[\" value\"].min())\n",
    "print(\"Max: \", interest[\" value\"].max())\n",
    "print(\"Mean: \", interest[\" value\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ba8a3",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "1. Data seems like what we would expect.\n",
    "2. Min, max and mean interest rates seem reasonable (no negative interest rates).\n",
    "3. We see the null values in the ' value' column here.\n",
    "4. ' values' column format with 2 decimals looks good. May round to 2 decimals like stock datasets.\n",
    "\n",
    "#### To do (Cumulative):\n",
    "1. Change 'date' column name to \"Date\".\n",
    "2. Change ' value' column name to \"Int_Rate\".\n",
    "3. Change 'date' column to datetime type.\n",
    "4. Look into null values in 'value' column.\n",
    "5. Round ' value' column to 2 decimals like stock datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eb7c059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interest Rates:\n",
      "\n",
      "1954-07-01    1\n",
      "1999-03-05    1\n",
      "1999-03-14    1\n",
      "1999-03-13    1\n",
      "1999-03-12    1\n",
      "             ..\n",
      "1976-11-01    1\n",
      "1976-10-31    1\n",
      "1976-10-30    1\n",
      "1976-10-29    1\n",
      "2022-11-30    1\n",
      "Name: date, Length: 24483, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm no duplicate date entries\n",
    "\n",
    "print(\"Interest Rates:\\n\")\n",
    "print(interest[\"date\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9b04b",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "1. No duplicate date entries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459cf60",
   "metadata": {},
   "source": [
    "# Let's clean interest rate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07994105",
   "metadata": {},
   "source": [
    "#### To do List (Cumulative):\n",
    "1. Change 'date' column name to \"Date\".\n",
    "2. Change ' value' column name to \"Int_Rate\".\n",
    "3. Change 'date' column to datetime type.\n",
    "4. Look into null values in 'value' column.\n",
    "5. Round ' value' column to 2 decimals like stock datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a7e2f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change 'date' column name to \"Date\".\n",
    "#Change ' value' column name to \"Int_Rate\".\n",
    "\n",
    "interest_clean = interest.rename(columns = {\"date\":\"Date\", \" value\":\"Int_Rate\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b295c820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Int_Rate'], dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interest_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "49dc13d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Int_Rate\n",
      "0  1954-07-01      1.13\n",
      "1  1954-07-02      1.25\n",
      "2  1954-07-03      1.25\n",
      "3  1954-07-04      1.25\n",
      "4  1954-07-05      0.88\n"
     ]
    }
   ],
   "source": [
    "# Round 'Int_Rate' column to 2 decimals (might be already but just to be sure)\n",
    "\n",
    "interest_clean[\"Int_Rate\"] = interest_clean[\"Int_Rate\"].round(2)\n",
    "\n",
    "print(interest_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "80c578a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24483 entries, 0 to 24482\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Date      24483 non-null  object \n",
      " 1   Int_Rate  24462 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 382.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Look into null values in 'Int_Rate' column.\n",
    "\n",
    "interest_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8769d2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Int_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24462</th>\n",
       "      <td>2022-11-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24463</th>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24464</th>\n",
       "      <td>2022-11-12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24465</th>\n",
       "      <td>2022-11-13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24466</th>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24467</th>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24468</th>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24469</th>\n",
       "      <td>2022-11-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24470</th>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24471</th>\n",
       "      <td>2022-11-19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24472</th>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24473</th>\n",
       "      <td>2022-11-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24474</th>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24475</th>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24476</th>\n",
       "      <td>2022-11-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24477</th>\n",
       "      <td>2022-11-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24478</th>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24479</th>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24480</th>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24482</th>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  Int_Rate\n",
       "24462  2022-11-10       NaN\n",
       "24463  2022-11-11       NaN\n",
       "24464  2022-11-12       NaN\n",
       "24465  2022-11-13       NaN\n",
       "24466  2022-11-14       NaN\n",
       "24467  2022-11-15       NaN\n",
       "24468  2022-11-16       NaN\n",
       "24469  2022-11-17       NaN\n",
       "24470  2022-11-18       NaN\n",
       "24471  2022-11-19       NaN\n",
       "24472  2022-11-20       NaN\n",
       "24473  2022-11-21       NaN\n",
       "24474  2022-11-22       NaN\n",
       "24475  2022-11-23       NaN\n",
       "24476  2022-11-24       NaN\n",
       "24477  2022-11-25       NaN\n",
       "24478  2022-11-26       NaN\n",
       "24479  2022-11-27       NaN\n",
       "24480  2022-11-28       NaN\n",
       "24481  2022-11-29       NaN\n",
       "24482  2022-11-30       NaN"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interest_clean[interest_clean[\"Int_Rate\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5f4e0424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24483\n",
      "24462\n"
     ]
    }
   ],
   "source": [
    "print(len(interest_clean))\n",
    "interest_clean = interest_clean.dropna(axis=0)\n",
    "print(len(interest_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "619ea9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24462 entries, 0 to 24461\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Date      24462 non-null  object \n",
      " 1   Int_Rate  24462 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 573.3+ KB\n"
     ]
    }
   ],
   "source": [
    "interest_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f66ea06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change \"Date\" column to datetime type\n",
    "interest_clean[\"Date\"] = pd.to_datetime(interest_clean[\"Date\"])\n",
    "\n",
    "print(interest_clean[\"Date\"].dtypes, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de51e397",
   "metadata": {},
   "source": [
    "# Let's merge cleaned dataframes into 1 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3352ec0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Amazon_Adj_Close</th>\n",
       "      <th>Amazon_Vol</th>\n",
       "      <th>Apple_Adj_Close</th>\n",
       "      <th>Apple_Vol</th>\n",
       "      <th>Facebook_Adj_Close</th>\n",
       "      <th>Facebook_Vol</th>\n",
       "      <th>Google_Adj_Close</th>\n",
       "      <th>Google_Vol</th>\n",
       "      <th>Netflix_Adj_Close</th>\n",
       "      <th>Netflix_Vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>1.96</td>\n",
       "      <td>72156000.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>99008000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-05-16</td>\n",
       "      <td>1.73</td>\n",
       "      <td>14700000.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>93296000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-05-19</td>\n",
       "      <td>1.71</td>\n",
       "      <td>6106800.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>52259200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-05-20</td>\n",
       "      <td>1.64</td>\n",
       "      <td>5467200.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>84828800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-05-21</td>\n",
       "      <td>1.43</td>\n",
       "      <td>18853200.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>122248000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.04</td>\n",
       "      <td>225702700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1629.53</td>\n",
       "      <td>1321100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.18</td>\n",
       "      <td>151948100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1655.08</td>\n",
       "      <td>1133800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10015</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1717.39</td>\n",
       "      <td>2476100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1629.51</td>\n",
       "      <td>3180200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10017</th>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1581.21</td>\n",
       "      <td>2792533.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10018 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Amazon_Adj_Close  Amazon_Vol  Apple_Adj_Close    Apple_Vol  \\\n",
       "0     1997-05-15              1.96  72156000.0             0.14   99008000.0   \n",
       "1     1997-05-16              1.73  14700000.0             0.13   93296000.0   \n",
       "2     1997-05-19              1.71   6106800.0             0.13   52259200.0   \n",
       "3     1997-05-20              1.64   5467200.0             0.13   84828800.0   \n",
       "4     1997-05-21              1.43  18853200.0             0.13  122248000.0   \n",
       "...          ...               ...         ...              ...          ...   \n",
       "10013 2020-08-31               NaN         NaN           129.04  225702700.0   \n",
       "10014 2020-09-01               NaN         NaN           134.18  151948100.0   \n",
       "10015 2020-09-02               NaN         NaN              NaN          NaN   \n",
       "10016 2020-09-03               NaN         NaN              NaN          NaN   \n",
       "10017 2020-09-04               NaN         NaN              NaN          NaN   \n",
       "\n",
       "       Facebook_Adj_Close  Facebook_Vol  Google_Adj_Close  Google_Vol  \\\n",
       "0                     NaN           NaN               NaN         NaN   \n",
       "1                     NaN           NaN               NaN         NaN   \n",
       "2                     NaN           NaN               NaN         NaN   \n",
       "3                     NaN           NaN               NaN         NaN   \n",
       "4                     NaN           NaN               NaN         NaN   \n",
       "...                   ...           ...               ...         ...   \n",
       "10013                 NaN           NaN           1629.53   1321100.0   \n",
       "10014                 NaN           NaN           1655.08   1133800.0   \n",
       "10015                 NaN           NaN           1717.39   2476100.0   \n",
       "10016                 NaN           NaN           1629.51   3180200.0   \n",
       "10017                 NaN           NaN           1581.21   2792533.0   \n",
       "\n",
       "       Netflix_Adj_Close  Netflix_Vol  \n",
       "0                    NaN          NaN  \n",
       "1                    NaN          NaN  \n",
       "2                    NaN          NaN  \n",
       "3                    NaN          NaN  \n",
       "4                    NaN          NaN  \n",
       "...                  ...          ...  \n",
       "10013                NaN          NaN  \n",
       "10014                NaN          NaN  \n",
       "10015                NaN          NaN  \n",
       "10016                NaN          NaN  \n",
       "10017                NaN          NaN  \n",
       "\n",
       "[10018 rows x 11 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First merge stock datasets on the \"Date\" fields (outer join; keeping all dates for now).\n",
    "\n",
    "merged_df = pd.merge(left = amazon_clean, right = apple_clean, on = \"Date\", how = \"outer\")\n",
    "merged_df = pd.merge(left = merged_df, right = facebook_clean, on = \"Date\", how = \"outer\")\n",
    "merged_df = pd.merge(left = merged_df, right = google_clean, on = \"Date\", how = \"outer\")\n",
    "merged_df = pd.merge(left = merged_df, right = netflix_clean, on = \"Date\", how = \"outer\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a679de46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10018 entries, 0 to 10017\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   Date                10018 non-null  datetime64[ns]\n",
      " 1   Amazon_Adj_Close    5852 non-null   float64       \n",
      " 2   Amazon_Vol          5852 non-null   float64       \n",
      " 3   Apple_Adj_Close     10015 non-null  float64       \n",
      " 4   Apple_Vol           10015 non-null  float64       \n",
      " 5   Facebook_Adj_Close  2076 non-null   float64       \n",
      " 6   Facebook_Vol        2076 non-null   float64       \n",
      " 7   Google_Adj_Close    4041 non-null   float64       \n",
      " 8   Google_Vol          4041 non-null   float64       \n",
      " 9   Netflix_Adj_Close   4581 non-null   float64       \n",
      " 10  Netflix_Vol         4581 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(10)\n",
      "memory usage: 939.2 KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d6044",
   "metadata": {},
   "source": [
    "#### Volume columns converted to floats due to merge. We are okay with this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7676d90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Amazon_Adj_Close</th>\n",
       "      <th>Amazon_Vol</th>\n",
       "      <th>Apple_Adj_Close</th>\n",
       "      <th>Apple_Vol</th>\n",
       "      <th>Facebook_Adj_Close</th>\n",
       "      <th>Facebook_Vol</th>\n",
       "      <th>Google_Adj_Close</th>\n",
       "      <th>Google_Vol</th>\n",
       "      <th>Netflix_Adj_Close</th>\n",
       "      <th>Netflix_Vol</th>\n",
       "      <th>Int_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>1.96</td>\n",
       "      <td>72156000.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>99008000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-05-16</td>\n",
       "      <td>1.73</td>\n",
       "      <td>14700000.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>93296000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-05-19</td>\n",
       "      <td>1.71</td>\n",
       "      <td>6106800.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>52259200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-05-20</td>\n",
       "      <td>1.64</td>\n",
       "      <td>5467200.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>84828800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-05-21</td>\n",
       "      <td>1.43</td>\n",
       "      <td>18853200.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>122248000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.04</td>\n",
       "      <td>225702700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1629.53</td>\n",
       "      <td>1321100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.18</td>\n",
       "      <td>151948100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1655.08</td>\n",
       "      <td>1133800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1717.39</td>\n",
       "      <td>2476100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1629.51</td>\n",
       "      <td>3180200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1581.21</td>\n",
       "      <td>2792533.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10014 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Amazon_Adj_Close  Amazon_Vol  Apple_Adj_Close    Apple_Vol  \\\n",
       "0     1997-05-15              1.96  72156000.0             0.14   99008000.0   \n",
       "1     1997-05-16              1.73  14700000.0             0.13   93296000.0   \n",
       "2     1997-05-19              1.71   6106800.0             0.13   52259200.0   \n",
       "3     1997-05-20              1.64   5467200.0             0.13   84828800.0   \n",
       "4     1997-05-21              1.43  18853200.0             0.13  122248000.0   \n",
       "...          ...               ...         ...              ...          ...   \n",
       "10009 2020-08-31               NaN         NaN           129.04  225702700.0   \n",
       "10010 2020-09-01               NaN         NaN           134.18  151948100.0   \n",
       "10011 2020-09-02               NaN         NaN              NaN          NaN   \n",
       "10012 2020-09-03               NaN         NaN              NaN          NaN   \n",
       "10013 2020-09-04               NaN         NaN              NaN          NaN   \n",
       "\n",
       "       Facebook_Adj_Close  Facebook_Vol  Google_Adj_Close  Google_Vol  \\\n",
       "0                     NaN           NaN               NaN         NaN   \n",
       "1                     NaN           NaN               NaN         NaN   \n",
       "2                     NaN           NaN               NaN         NaN   \n",
       "3                     NaN           NaN               NaN         NaN   \n",
       "4                     NaN           NaN               NaN         NaN   \n",
       "...                   ...           ...               ...         ...   \n",
       "10009                 NaN           NaN           1629.53   1321100.0   \n",
       "10010                 NaN           NaN           1655.08   1133800.0   \n",
       "10011                 NaN           NaN           1717.39   2476100.0   \n",
       "10012                 NaN           NaN           1629.51   3180200.0   \n",
       "10013                 NaN           NaN           1581.21   2792533.0   \n",
       "\n",
       "       Netflix_Adj_Close  Netflix_Vol  Int_Rate  \n",
       "0                    NaN          NaN      5.71  \n",
       "1                    NaN          NaN      5.44  \n",
       "2                    NaN          NaN      5.55  \n",
       "3                    NaN          NaN      5.51  \n",
       "4                    NaN          NaN      5.56  \n",
       "...                  ...          ...       ...  \n",
       "10009                NaN          NaN      0.09  \n",
       "10010                NaN          NaN      0.09  \n",
       "10011                NaN          NaN      0.09  \n",
       "10012                NaN          NaN      0.09  \n",
       "10013                NaN          NaN      0.09  \n",
       "\n",
       "[10014 rows x 12 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now merge interest rate dataset on the \"Date\" fields (inner join; don't need interest rates where no data\n",
    "# on stocks).\n",
    "\n",
    "merged_df = pd.merge(left = merged_df, right = interest_clean, on = \"Date\", how = \"inner\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1ab04c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Amazon_Adj_Close</th>\n",
       "      <th>Amazon_Vol</th>\n",
       "      <th>Apple_Adj_Close</th>\n",
       "      <th>Apple_Vol</th>\n",
       "      <th>Facebook_Adj_Close</th>\n",
       "      <th>Facebook_Vol</th>\n",
       "      <th>Google_Adj_Close</th>\n",
       "      <th>Google_Vol</th>\n",
       "      <th>Netflix_Adj_Close</th>\n",
       "      <th>Netflix_Vol</th>\n",
       "      <th>Int_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>469033600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>175884800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>105728000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5851</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>86441600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5852</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>73449600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.04</td>\n",
       "      <td>225702700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1629.53</td>\n",
       "      <td>1321100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.18</td>\n",
       "      <td>151948100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1655.08</td>\n",
       "      <td>1133800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1717.39</td>\n",
       "      <td>2476100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1629.51</td>\n",
       "      <td>3180200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1581.21</td>\n",
       "      <td>2792533.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10014 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Amazon_Adj_Close  Amazon_Vol  Apple_Adj_Close    Apple_Vol  \\\n",
       "5848  1980-12-12               NaN         NaN             0.10  469033600.0   \n",
       "5849  1980-12-15               NaN         NaN             0.10  175884800.0   \n",
       "5850  1980-12-16               NaN         NaN             0.09  105728000.0   \n",
       "5851  1980-12-17               NaN         NaN             0.09   86441600.0   \n",
       "5852  1980-12-18               NaN         NaN             0.09   73449600.0   \n",
       "...          ...               ...         ...              ...          ...   \n",
       "10009 2020-08-31               NaN         NaN           129.04  225702700.0   \n",
       "10010 2020-09-01               NaN         NaN           134.18  151948100.0   \n",
       "10011 2020-09-02               NaN         NaN              NaN          NaN   \n",
       "10012 2020-09-03               NaN         NaN              NaN          NaN   \n",
       "10013 2020-09-04               NaN         NaN              NaN          NaN   \n",
       "\n",
       "       Facebook_Adj_Close  Facebook_Vol  Google_Adj_Close  Google_Vol  \\\n",
       "5848                  NaN           NaN               NaN         NaN   \n",
       "5849                  NaN           NaN               NaN         NaN   \n",
       "5850                  NaN           NaN               NaN         NaN   \n",
       "5851                  NaN           NaN               NaN         NaN   \n",
       "5852                  NaN           NaN               NaN         NaN   \n",
       "...                   ...           ...               ...         ...   \n",
       "10009                 NaN           NaN           1629.53   1321100.0   \n",
       "10010                 NaN           NaN           1655.08   1133800.0   \n",
       "10011                 NaN           NaN           1717.39   2476100.0   \n",
       "10012                 NaN           NaN           1629.51   3180200.0   \n",
       "10013                 NaN           NaN           1581.21   2792533.0   \n",
       "\n",
       "       Netflix_Adj_Close  Netflix_Vol  Int_Rate  \n",
       "5848                 NaN          NaN     19.44  \n",
       "5849                 NaN          NaN     19.62  \n",
       "5850                 NaN          NaN     20.45  \n",
       "5851                 NaN          NaN     20.27  \n",
       "5852                 NaN          NaN     20.74  \n",
       "...                  ...          ...       ...  \n",
       "10009                NaN          NaN      0.09  \n",
       "10010                NaN          NaN      0.09  \n",
       "10011                NaN          NaN      0.09  \n",
       "10012                NaN          NaN      0.09  \n",
       "10013                NaN          NaN      0.09  \n",
       "\n",
       "[10014 rows x 12 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort merged_df by date ascending\n",
    "\n",
    "merged_df = merged_df.sort_values(\"Date\", ascending=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "af48b17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Amazon_Adj_Close</th>\n",
       "      <th>Amazon_Vol</th>\n",
       "      <th>Apple_Adj_Close</th>\n",
       "      <th>Apple_Vol</th>\n",
       "      <th>Facebook_Adj_Close</th>\n",
       "      <th>Facebook_Vol</th>\n",
       "      <th>Google_Adj_Close</th>\n",
       "      <th>Google_Vol</th>\n",
       "      <th>Netflix_Adj_Close</th>\n",
       "      <th>Netflix_Vol</th>\n",
       "      <th>Int_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>469033600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>175884800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>105728000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>86441600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "      <td>73449600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129.04</td>\n",
       "      <td>225702700.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1629.53</td>\n",
       "      <td>1321100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134.18</td>\n",
       "      <td>151948100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1655.08</td>\n",
       "      <td>1133800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1717.39</td>\n",
       "      <td>2476100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1629.51</td>\n",
       "      <td>3180200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1581.21</td>\n",
       "      <td>2792533.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10014 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Amazon_Adj_Close  Amazon_Vol  Apple_Adj_Close    Apple_Vol  \\\n",
       "0     1980-12-12               NaN         NaN             0.10  469033600.0   \n",
       "1     1980-12-15               NaN         NaN             0.10  175884800.0   \n",
       "2     1980-12-16               NaN         NaN             0.09  105728000.0   \n",
       "3     1980-12-17               NaN         NaN             0.09   86441600.0   \n",
       "4     1980-12-18               NaN         NaN             0.09   73449600.0   \n",
       "...          ...               ...         ...              ...          ...   \n",
       "10009 2020-08-31               NaN         NaN           129.04  225702700.0   \n",
       "10010 2020-09-01               NaN         NaN           134.18  151948100.0   \n",
       "10011 2020-09-02               NaN         NaN              NaN          NaN   \n",
       "10012 2020-09-03               NaN         NaN              NaN          NaN   \n",
       "10013 2020-09-04               NaN         NaN              NaN          NaN   \n",
       "\n",
       "       Facebook_Adj_Close  Facebook_Vol  Google_Adj_Close  Google_Vol  \\\n",
       "0                     NaN           NaN               NaN         NaN   \n",
       "1                     NaN           NaN               NaN         NaN   \n",
       "2                     NaN           NaN               NaN         NaN   \n",
       "3                     NaN           NaN               NaN         NaN   \n",
       "4                     NaN           NaN               NaN         NaN   \n",
       "...                   ...           ...               ...         ...   \n",
       "10009                 NaN           NaN           1629.53   1321100.0   \n",
       "10010                 NaN           NaN           1655.08   1133800.0   \n",
       "10011                 NaN           NaN           1717.39   2476100.0   \n",
       "10012                 NaN           NaN           1629.51   3180200.0   \n",
       "10013                 NaN           NaN           1581.21   2792533.0   \n",
       "\n",
       "       Netflix_Adj_Close  Netflix_Vol  Int_Rate  \n",
       "0                    NaN          NaN     19.44  \n",
       "1                    NaN          NaN     19.62  \n",
       "2                    NaN          NaN     20.45  \n",
       "3                    NaN          NaN     20.27  \n",
       "4                    NaN          NaN     20.74  \n",
       "...                  ...          ...       ...  \n",
       "10009                NaN          NaN      0.09  \n",
       "10010                NaN          NaN      0.09  \n",
       "10011                NaN          NaN      0.09  \n",
       "10012                NaN          NaN      0.09  \n",
       "10013                NaN          NaN      0.09  \n",
       "\n",
       "[10014 rows x 12 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset index of dataframe\n",
    "\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "18632e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clean, merged dataframe to csv\n",
    "\n",
    "merged_df.to_csv(\"Cleaned_Merged.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
